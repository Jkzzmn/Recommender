import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yaml
import sys
import os
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# 1. ê²½ë¡œ ì„¤ì • (srcë¥¼ ì°¾ê¸° ìœ„í•¨)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.model import MatrixFactorization # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ NCF ëª¨ë¸
from src.dataset import MovieDataset

def run_integrated_evaluation():
    # 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)

    data = pd.read_csv(config['path']['data_path'])
    n_users = data['user'].nunique()
    n_movies = data['movie'].nunique()

    X = data[['user', 'movie']].values
    y = data['rating'].values

    # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ split ìœ ì§€
    _, X_test, _, y_test = train_test_split(
        X, y, 
        test_size=config['train']['test_size'], 
        random_state=config['train']['random_state']
    )

    # 2. ëª¨ë¸ ë¡œë“œ (v2 ê¸°ì¤€)
    model = MatrixFactorization(
        n_users, 
        n_movies, 
        embedding_dim=config['model']['embedding_dim']
    )
    model.load_state_dict(torch.load(config['path']['model_path']))
    model.eval()

    # 3. ì˜ˆì¸¡ê°’ ì¶”ì¶œ ë° ìˆ˜ì¹˜ ì§€í‘œ ê³„ì‚°
    with torch.no_grad():
        users = torch.LongTensor(X_test[:, 0])
        movies = torch.LongTensor(X_test[:, 1])
        all_preds = model(users, movies).numpy()

    # RMSE ê³„ì‚°
    rmse = np.sqrt(mean_squared_error(y_test, all_preds))

    # Precision@K, Recall@K ê³„ì‚°
    k = 10
    threshold = 4.0
    test_df = pd.DataFrame(X_test, columns=['user', 'movie'])
    test_df['actual'] = y_test
    test_df['pred'] = all_preds
    
    precisions, recalls = [], []
    for _, group in test_df.groupby('user'):
        actual_liked = group[group['actual'] >= threshold]['movie'].tolist()
        if not actual_liked: continue
        
        top_k_recs = group.sort_values(by='pred', ascending=False).head(k)['movie'].tolist()
        hits = len(set(actual_liked) & set(top_k_recs))
        precisions.append(hits / k)
        recalls.append(hits / len(actual_liked))

    # 4. ê²°ê³¼ ì¶œë ¥
    print("="*40)
    print(f"ğŸš€ Matrix Factorization ê²°ê³¼ (Top-{k})")
    print(f"1. RMSE      : {rmse:.4f}")
    print(f"2. Precision : {np.mean(precisions)*100:.2f}%")
    print(f"3. Recall    : {np.mean(recalls)*100:.2f}%")
    print("="*40)

    # 5. ì‹œê°í™” (Analysis ê¸°ëŠ¥)
    plt.figure(figsize=(14, 6))
    
    # [ì™¼ìª½] ë¶„í¬ ë¹„êµ
    plt.subplot(1, 2, 1)
    sns.histplot(y_test, bins=5, color='red', alpha=0.3, label='Actual', kde=False)
    sns.histplot(all_preds, bins=30, color='blue', alpha=0.5, label='Predicted', kde=True)
    plt.title('Rating Distribution')
    plt.legend()
    
    # [ì˜¤ë¥¸ìª½] ì˜¤ì°¨ ë¶„í¬
    plt.subplot(1, 2, 2)
    errors = y_test - all_preds
    sns.histplot(errors, bins=30, kde=True, color='green')
    plt.axvline(x=0, color='black', linestyle='--')
    plt.title('Prediction Error Distribution')
    
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    run_integrated_evaluation()