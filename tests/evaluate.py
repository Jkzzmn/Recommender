import torch
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import yaml

from src.model import MatrixFactorization
from src.dataset import MovieDataset
from analysis import plot_analysis

# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

data = pd.read_csv(config['path']['data_path'])
n_users = data['user'].nunique()
n_movies = data['movie'].nunique()

X = data[['user', 'movie']].values
y = data['rating'].values

# í•™ìŠµ ë•Œì™€ ë™ì¼í•œ split ìœ ì§€
_, X_test, _, y_test = train_test_split(
    X, y, test_size=config['train']['test_size'], random_state=config['train']['random_state']
)

test_loader = DataLoader(MovieDataset(X_test, y_test), batch_size=config['train']['batch_size'], shuffle=False)

# 2. ëª¨ë¸ ë¡œë“œ
model = MatrixFactorization(n_users, n_movies, embedding_dim=config['model']['embedding_dim'])
model.load_state_dict(torch.load(config['path']['model_path']))
model.eval()

# 3. ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ë“¤
def get_metrics(model, X_test, y_test, k=10, threshold=4.0):
    all_preds = []
    all_targets = y_test
    
    # RMSEë¥¼ ìœ„í•œ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
    with torch.no_grad():
        users = torch.LongTensor(X_test[:, 0])
        movies = torch.LongTensor(X_test[:, 1])
        preds = model(users, movies)
        all_preds = preds.numpy()

    rmse = np.sqrt(mean_squared_error(all_targets, all_preds))

    # Precision@K & Recall@K ê³„ì‚°ì„ ìœ„í•´ ë°ì´í„° ì •ë¦¬
    # ìœ ì €ë³„ë¡œ ë¬¶ì–´ì„œ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤.
    test_df = pd.DataFrame(X_test, columns=['user', 'movie'])
    test_df['actual'] = y_test
    test_df['pred'] = all_preds
    
    precisions = []
    recalls = []
    
    for user_id, group in test_df.groupby('user'):
        # ìœ ì €ê°€ ì‹¤ì œë¡œ ì¢‹ì•„í•œ ì˜í™” (ê¸°ì¤€ ì ìˆ˜ ì´ìƒ)
        actual_liked = group[group['actual'] >= threshold]['movie'].tolist()
        if not actual_liked: continue # ì¢‹ì•„í•œ ì˜í™”ê°€ ì—†ìœ¼ë©´ ê³„ì‚° ì œì™¸
        
        # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ìƒìœ„ Kê°œ ì˜í™”
        top_k_recs = group.sort_values(by='pred', ascending=False).head(k)['movie'].tolist()
        
        # ë§íŒ ê°œìˆ˜ (Intersection)
        hits = len(set(actual_liked) & set(top_k_recs))
        
        # Precision@K: ì¶”ì²œí•œ Kê°œ ì¤‘ ë§íŒ ë¹„ìœ¨
        precisions.append(hits / k)
        # Recall@K: ìœ ì €ê°€ ì¢‹ì•„í•œ ì „ì²´ ì¤‘ ë§íŒ ë¹„ìœ¨
        recalls.append(hits / len(actual_liked))
        
    return rmse, np.mean(precisions), np.mean(recalls)

# 4. ì‹¤í–‰ ë° ì¶œë ¥
k_value = 10
rmse, precision, recall = get_metrics(model, X_test, y_test, k=k_value)

print("="*40)
print(f"ğŸš€ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ (Top-{k_value})")
print(f"1. RMSE      : {rmse:.4f} (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
print(f"2. Precision : {precision*100:.2f}% (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
print(f"3. Recall    : {recall*100:.2f}% (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
print("="*40)
