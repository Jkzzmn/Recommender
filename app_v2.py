import streamlit as st
import torch
import pandas as pd
import numpy as np
import yaml
from src.model import NeuralCF

# --- 1. ì„¤ì • ë° ë¦¬ì†ŒìŠ¤ ë¡œë“œ ---
@st.cache_resource
def load_resources():
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # ì „ì²˜ë¦¬ëœ ìµœì¢… ë°ì´í„° ë¡œë“œ (ìœ ì €ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ê¸° ìœ„í•¨)
    data = pd.read_csv(config['path']['data_v2_path'])
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
    n_users = data['user_id'].max() + 1
    n_movies = data['movie_id'].max() + 1
    
    # extra_cols ì •ì˜ (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ìˆœì„œì—¬ì•¼ í•¨)
    target_col = 'rating'
    id_cols = ['user_id', 'movie_id']
    extra_cols = [c for c in data.columns if c not in id_cols + [target_col]]
    extra_dim = len(extra_cols)
    
    # ëª¨ë¸ ë¡œë“œ
    model = NeuralCF(
        n_users, 
        n_movies, 
        embedding_dim=config['model_v2']['embedding_dim'],
        extra_dim=extra_dim
    )
    model.load_state_dict(torch.load(config['path']['model_v2_path'], map_location='cpu'))
    model.eval()
    
    # ì˜í™” ì œëª© ë§¤í•‘ (u.item í™œìš© ë˜ëŠ” ë°ì´í„°í”„ë ˆì„ ë‚´ movie_titleì´ ìˆë‹¤ë©´ ì‚¬ìš©)
    # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ movie_idë¡œ í‘œì‹œí•˜ê±°ë‚˜ ë³„ë„ì˜ ì˜í™” ì •ë³´ íŒŒì¼ì„ mergeí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
    return data, model, extra_cols, config

data, model, extra_cols, config = load_resources()

# --- 2. ì›¹ í™”ë©´ êµ¬ì„± ---
st.set_page_config(page_title="ëŒ€í˜„ì˜ AI ì¶”ì²œ v2", page_icon="ğŸ¿")
st.title("ğŸ¬ ëŒ€í˜„ì˜ ì§€ëŠ¥í˜• ì˜í™” ì¶”ì²œ ì‹œìŠ¤í…œ (v2)")
st.markdown(f"**í˜„ì¬ ë°˜ì˜ëœ í”¼ì²˜:** ì¥ë¥´, ë‚˜ì´ëŒ€, ì„±ë³„, ì§ì—… (ì´ {len(extra_cols)}ê°œ)")

user_id_input = st.number_input("ìœ ì € IDë¥¼ ì…ë ¥í•˜ì„¸ìš”", min_value=0, step=1)

if st.button("ì¶”ì²œ ë°›ê¸°"):
    if user_id_input in data['user_id'].unique():
        # 1. í•´ë‹¹ ìœ ì €ì˜ ë©”íƒ€ë°ì´í„°(ë‚˜ì´, ì„±ë³„ ë“±) ê°€ì ¸ì˜¤ê¸°
        user_meta = data[data['user_id'] == user_id_input].iloc[0]
        
        # 2. ëª¨ë“  ì˜í™” ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
        all_movie_ids = data['movie_id'].unique()
        n_all_movies = len(all_movie_ids)
        
        # 3. ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ í…ì„œ ìƒì„±
        u_tensor = torch.LongTensor([user_id_input] * n_all_movies)
        m_tensor = torch.LongTensor(all_movie_ids)
        
        # ìœ ì € ë©”íƒ€ë°ì´í„°(extra_features) ë³µì œ
        # í•´ë‹¹ ìœ ì €ì˜ ê³ ì •ëœ í”¼ì²˜(ì¥ë¥´ ì œì™¸í•œ ìœ ì € í”¼ì²˜ + ì˜í™”ë³„ ì¥ë¥´ë¥¼ í•©ì³ì•¼ ì •í™•í•˜ì§€ë§Œ, 
        # ì¼ë‹¨ ê°€ì¥ ê°„ë‹¨í•˜ê²Œ í•´ë‹¹ ìœ ì €ê°€ ë³¸ í‰ê· ì ì¸ íŠ¹ì§•ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê±°ë‚˜ 
        # ì˜í™”ë³„ ì¥ë¥´ ì •ë³´ë¥¼ ë§¤í•‘í•´ì„œ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.)
        
        # [ì •ì„ì ì¸ ë°©ë²•] ê° ì˜í™”ì˜ ì¥ë¥´ ì •ë³´ì™€ ìœ ì €ì˜ ì •ë³´ë¥¼ í•©ì¹œ extra_features í–‰ë ¬ ìƒì„±
        movie_info = data.drop_duplicates('movie_id').set_index('movie_id')[extra_cols]
        user_extra_features = movie_info.copy()
        
        # ìœ ì € ê³ ìœ  ì •ë³´(ë‚˜ì´, ì„±ë³„ ë“±)ëŠ” ë™ì¼í•˜ê²Œ ë³µì‚¬í•˜ê³  ì¥ë¥´ë§Œ ì˜í™” ì •ë³´ë¥¼ ë”°ë¦„
        user_cols = [c for c in extra_cols if 'gen_' in c or 'occ_' in c or 'age_' in c]
        for col in user_cols:
            user_extra_features[col] = user_meta[col]
            
        e_tensor = torch.FloatTensor(user_extra_features.loc[all_movie_ids].values)
        
        # 4. ì˜ˆì¸¡
        with torch.no_grad():
            predictions = model(u_tensor, m_tensor, e_tensor)
        
        # 5. ê²°ê³¼ ì •ë¦¬
        top_k = 10
        scores, indices = torch.topk(predictions, k=top_k)
        
        st.subheader(f"âœ… ìœ ì € {user_id_input}ë‹˜ê»˜ ì¶”ì²œí•˜ëŠ” ì˜í™”")
        
        rec_data = []
        for i in range(top_k):
            m_id = all_movie_ids[indices[i].item()]
            score = scores[i].item()
            rec_data.append({"ìˆœìœ„": i+1, "Movie ID": m_id, "ì¶”ì²œ ì ìˆ˜": f"{score:.2f}ì "})
            
        st.table(pd.DataFrame(rec_data))
        st.success("ìœ ì €ë‹˜ì˜ ë‚˜ì´ëŒ€ì™€ ì§ì—…, ì˜í™” ì¥ë¥´ ì·¨í–¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì˜í™”ë¥¼ ì°¾ì•„ëƒˆìŠµë‹ˆë‹¤!")
    else:
        st.error("ë°ì´í„°ì…‹ì— ì—†ëŠ” ìœ ì €ì…ë‹ˆë‹¤.")